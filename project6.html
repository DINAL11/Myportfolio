<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Large-Scale Data Processing & Analytics - Dinal Dholiya</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600;700;800&family=Orbitron:wght@500;700;900&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="project-styles.css">
</head>
<body>
    <!-- Animated Background -->
    <div class="animated-bg">
        <div class="gradient-orb orb-1"></div>
        <div class="gradient-orb orb-2"></div>
    </div>

    <!-- Navigation -->
    <nav class="nav-header">
        <div class="nav-container">
            <a href="index.html" class="back-btn">
                <i class="fas fa-arrow-left"></i>
                <span>Back to Portfolio</span>
            </a>
            <div class="project-title-nav">Big Data Analytics</div>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero-section">
        <div class="hero-badge">
            <i class="fas fa-database"></i>
            <span>Big Data • Hadoop • Spark • Machine Learning</span>
        </div>
        <h1 class="hero-title">Large-Scale Data Processing & Analytics Pipeline</h1>
        <p class="hero-subtitle">
            End-to-end data workflow using Hadoop and Spark for large-scale processing, exploratory data analysis, 
            and machine learning model development with comprehensive metrics analysis.
        </p>
        <div class="hero-links">
            <a class="button" href="https://drive.google.com/file/d/1IKZLe6SwVGdBUJtRXf1iPH984Ot8AK-p/view?usp=sharing" target="_blank">
                <i class="fas fa-file-pdf"></i>Data Engineering Report
            </a>
            <a class="button" href="https://drive.google.com/file/d/18nuGHvCHpsiyb9lucAquJYT_s2N-VZdR/view" target="_blank">
                <i class="fas fa-file-pdf"></i>ML Report
            </a>
        </div>
    </section>

    <!-- Main Content -->
    <div class="container">
        <!-- Project Overview -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-info-circle"></i></div>
                <h2>Project Overview</h2>
            </div>
            <p>
                This project demonstrates the complete lifecycle of large-scale data analytics, from ingestion and 
                processing using distributed systems to advanced machine learning model development. The pipeline 
                handles over 1 million rows of data, applying sophisticated transformation methods and building 
                multiple ML models with rigorous evaluation.
            </p>
        </div>

        <!-- Project Goals -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-bullseye"></i></div>
                <h2>Project Goals</h2>
            </div>
            <ul>
                <li>Build scalable data processing pipeline using Hadoop and Spark</li>
                <li>Perform comprehensive exploratory data analysis on large datasets</li>
                <li>Apply 10+ data transformation and preprocessing methods</li>
                <li>Develop and evaluate multiple machine learning models</li>
                <li>Implement cross-validation and advanced metrics analysis</li>
                <li>Create reproducible and well-documented workflows</li>
            </ul>
        </div>

        <!-- Data Processing Pipeline -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-stream"></i></div>
                <h2>Data Processing Pipeline</h2>
            </div>
            
            <h3><i class="fas fa-download"></i> Data Ingestion</h3>
            <ul>
                <li>Processed datasets with <strong>1M+ rows</strong> using Hadoop HDFS</li>
                <li>Implemented efficient data partitioning strategies</li>
                <li>Created data validation and quality checks</li>
                <li>Designed schema evolution handling mechanisms</li>
            </ul>

            <h3><i class="fas fa-cogs"></i> Data Transformation</h3>
            <ul>
                <li>Applied <strong>10+ transformation methods</strong> including normalization, scaling, and encoding</li>
                <li>Handled missing values with multiple imputation strategies</li>
                <li>Performed feature engineering and selection</li>
                <li>Created derived features for enhanced model performance</li>
            </ul>

            <h3><i class="fas fa-chart-pie"></i> Exploratory Data Analysis</h3>
            <ul>
                <li>Comprehensive statistical analysis of data distributions</li>
                <li>Correlation analysis and multicollinearity detection</li>
                <li>Outlier detection and treatment strategies</li>
                <li>Interactive visualizations for data insights</li>
            </ul>
        </div>

        <!-- Machine Learning Models -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-brain"></i></div>
                <h2>Machine Learning Models</h2>
            </div>
            
            <div class="stats-grid">
                <div class="stat-card">
                    <span class="stat-number">5+</span>
                    <span class="stat-label">ML Models</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">1M+</span>
                    <span class="stat-label">Data Points</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">10+</span>
                    <span class="stat-label">Transformations</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">K-Fold</span>
                    <span class="stat-label">Cross-Validation</span>
                </div>
            </div>

            <h3><i class="fas fa-project-diagram"></i> Models Implemented</h3>
            <ul>
                <li><strong>Logistic Regression:</strong> Baseline classification model</li>
                <li><strong>Random Forest:</strong> Ensemble method for robust predictions</li>
                <li><strong>Gradient Boosting:</strong> Advanced boosting techniques (XGBoost, LightGBM)</li>
                <li><strong>Support Vector Machines:</strong> High-dimensional classification</li>
                <li><strong>Neural Networks:</strong> Deep learning for complex patterns</li>
            </ul>

            <h3><i class="fas fa-check-double"></i> Model Evaluation</h3>
            <ul>
                <li>K-fold cross-validation for robust performance estimation</li>
                <li>Multiple metrics: Accuracy, Precision, Recall, F1-Score, AUC-ROC</li>
                <li>Confusion matrix analysis for classification insights</li>
                <li>Feature importance and model interpretability</li>
                <li>Hyperparameter tuning using Grid Search and Random Search</li>
            </ul>
        </div>

        <!-- Technical Implementation -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-code"></i></div>
                <h2>Technical Implementation</h2>
            </div>
            
            <h3><i class="fas fa-server"></i> Big Data Technologies</h3>
            <ul>
                <li><strong>Hadoop:</strong> Distributed storage and MapReduce processing</li>
                <li><strong>Apache Spark:</strong> In-memory data processing and analytics</li>
                <li><strong>PySpark:</strong> Python API for Spark operations</li>
                <li>Spark SQL for efficient data querying and manipulation</li>
                <li>Spark MLlib for scalable machine learning</li>
            </ul>

            <h3><i class="fas fa-chart-line"></i> Data Science Stack</h3>
            <ul>
                <li><strong>Python:</strong> Primary programming language</li>
                <li><strong>Pandas & NumPy:</strong> Data manipulation and numerical computing</li>
                <li><strong>Scikit-learn:</strong> Machine learning algorithms and utilities</li>
                <li><strong>Matplotlib & Seaborn:</strong> Data visualization</li>
                <li>Jupyter Notebooks for interactive analysis</li>
            </ul>

            <h3><i class="fas fa-tasks"></i> Workflow Management</h3>
            <ul>
                <li>Modular pipeline design for reproducibility</li>
                <li>Version control for data and code</li>
                <li>Automated testing for data quality</li>
                <li>Comprehensive documentation and logging</li>
            </ul>
        </div>

        <!-- Key Achievements -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-trophy"></i></div>
                <h2>Key Achievements</h2>
            </div>
            <ul>
                <li>Successfully processed and analyzed <strong>1M+ rows</strong> of complex data</li>
                <li>Achieved <strong>92%+ accuracy</strong> on validation datasets</li>
                <li>Reduced processing time by <strong>60%</strong> using Spark optimization</li>
                <li>Implemented <strong>10+ feature engineering</strong> techniques</li>
                <li>Created comprehensive reports with actionable insights</li>
                <li>Developed reusable pipeline components for future projects</li>
            </ul>
        </div>

        <!-- Data Preprocessing Methods -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-tools"></i></div>
                <h2>Data Preprocessing Methods</h2>
            </div>
            <ul>
                <li><strong>Missing Value Handling:</strong> Mean/Median imputation, KNN imputation</li>
                <li><strong>Scaling & Normalization:</strong> StandardScaler, MinMaxScaler, RobustScaler</li>
                <li><strong>Encoding:</strong> One-Hot Encoding, Label Encoding, Target Encoding</li>
                <li><strong>Feature Selection:</strong> Correlation analysis, Recursive Feature Elimination</li>
                <li><strong>Outlier Treatment:</strong> IQR method, Z-score filtering</li>
                <li><strong>Dimensionality Reduction:</strong> PCA, Feature importance ranking</li>
                <li><strong>Class Balancing:</strong> SMOTE, Random Undersampling</li>
                <li><strong>Text Processing:</strong> Tokenization, TF-IDF vectorization</li>
                <li><strong>Date/Time Engineering:</strong> Cyclical encoding, Time-based features</li>
                <li><strong>Binning:</strong> Equal-width, Equal-frequency binning</li>
            </ul>
        </div>

        <!-- Visualization & Insights -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-chart-bar"></i></div>
                <h2>Visualization & Insights</h2>
            </div>
            <ul>
                <li>Distribution plots for understanding data characteristics</li>
                <li>Correlation heatmaps for feature relationships</li>
                <li>ROC curves and Precision-Recall curves for model performance</li>
                <li>Learning curves to diagnose bias-variance tradeoff</li>
                <li>Feature importance visualizations</li>
                <li>Confusion matrices for classification analysis</li>
            </ul>
        </div>

        <!-- Technologies Used -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-toolbox"></i></div>
                <h2>Technologies Used</h2>
            </div>
            <div class="stats-grid">
                <div class="stat-card">
                    <span class="stat-number">Hadoop</span>
                    <span class="stat-label">Distributed Storage</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">Spark</span>
                    <span class="stat-label">Processing Engine</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">Python</span>
                    <span class="stat-label">Programming</span>
                </div>
                <div class="stat-card">
                    <span class="stat-number">Scikit-learn</span>
                    <span class="stat-label">ML Framework</span>
                </div>
            </div>
            <ul>
                <li><strong>Big Data:</strong> Hadoop, Apache Spark, PySpark</li>
                <li><strong>Programming:</strong> Python, SQL</li>
                <li><strong>Data Processing:</strong> Pandas, NumPy, Spark DataFrames</li>
                <li><strong>Machine Learning:</strong> Scikit-learn, Spark MLlib</li>
                <li><strong>Visualization:</strong> Matplotlib, Seaborn, Plotly</li>
                <li><strong>Development:</strong> Jupyter Notebooks, Git</li>
            </ul>
        </div>

        <!-- Lessons Learned -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-lightbulb"></i></div>
                <h2>Lessons Learned</h2>
            </div>
            <ul>
                <li>Importance of data quality and preprocessing in model performance</li>
                <li>Benefits of distributed computing for large-scale data processing</li>
                <li>Value of comprehensive EDA before model development</li>
                <li>Tradeoffs between model complexity and interpretability</li>
                <li>Significance of proper validation strategies</li>
                <li>Need for scalable and maintainable code architecture</li>
            </ul>
        </div>

        <!-- Future Enhancements -->
        <div class="section">
            <div class="section-header">
                <div class="section-icon"><i class="fas fa-rocket"></i></div>
                <h2>Future Enhancements</h2>
            </div>
            <ul>
                <li>Real-time streaming data processing with Spark Streaming</li>
                <li>Deep learning models using TensorFlow on Spark</li>
                <li>AutoML integration for automated model selection</li>
                <li>Interactive dashboards for stakeholder insights</li>
                <li>Model deployment and monitoring pipeline</li>
                <li>Integration with cloud platforms (AWS, Azure, GCP)</li>
            </ul>
        </div>
    </div>

    <!-- Footer -->
    <footer>
        <p>&copy; 2024 Dinal Dholiya. All rights reserved.</p>
        <p><a href="index.html">← Back to Portfolio</a></p>
    </footer>
</body>
</html>